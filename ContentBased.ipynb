{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rake_nltk import Rake\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"\n",
    "        Load events from files and convert to dataframe.\n",
    "    \"\"\"\n",
    "    map_lst=[]\n",
    "    for f in os.listdir(path):\n",
    "        file_name=os.path.join(path,f)\n",
    "        if os.path.isfile(file_name):\n",
    "            for line in open(file_name):\n",
    "                obj = json.loads(line.strip())\n",
    "                if not obj is None:\n",
    "                    map_lst.append(obj)\n",
    "    return pd.DataFrame(map_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lower_case(text):\n",
    "    try:\n",
    "        return text.lower()\n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "def remove_stop_words(text):\n",
    "    text = text.split()\n",
    "    stops = set(stopwords.words(\"norwegian\"))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    texts = [w for w in text if w.isalpha()]\n",
    "    texts = \" \".join(texts)\n",
    "    return texts\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text = tokenizer.tokenize(text)\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_processing(df):\n",
    "    df = df.loc[(df[\"url\"] != \"http://adressa.no\")]\n",
    "    df = df.dropna(subset=['title'])\n",
    "    df = df.drop_duplicates(subset='title', keep=\"first\")\n",
    "\n",
    "    df['cleaned_title'] = df['title'].apply(func = make_lower_case)\n",
    "    df['cleaned_title'] = df.cleaned_title.apply(func = remove_stop_words)\n",
    "    df['cleaned_title'] = df.cleaned_title.apply(func = remove_punctuation)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(\"active1000\")\n",
    "\n",
    "df_updated = content_processing(df)\n",
    "\n",
    "train_data, test_data = train_test_split(df_updated, test_size=0.2, random_state=42)\n",
    "\n",
    "# vectorize the train and test data\n",
    "tfidf = TfidfVectorizer()\n",
    "train_tfidf_matrix = tfidf.fit_transform(train_data['title'])\n",
    "test_tfidf_matrix = tfidf.transform(test_data['title'])\n",
    "\n",
    "# calculate the similarity between train and test data\n",
    "cosine_sim = cosine_similarity(test_tfidf_matrix, train_tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_articles(article):\n",
    "    # vectorize the article keywords\n",
    "    article_vec = tfidf.transform([article])\n",
    "    # calculate the similarity\n",
    "    sim_scores = cosine_similarity(article_vec, train_tfidf_matrix)\n",
    "    # get the most similar articles\n",
    "    sim_scores = sim_scores[0]\n",
    "    article_indices = sim_scores.argsort()[::-1][:10]\n",
    "    #article_scores = sim_scores[article_indices]\n",
    "    #article_indices = article_indices[article_scores > threshold]\n",
    "    return train_data['title'].iloc[article_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_system(test_data, recommend_articles):\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    for i in range(len(test_data)):\n",
    "        keywords = test_data.iloc[i]['title']\n",
    "        actual_article = set(test_data.iloc[i]['title'].split('|'))\n",
    "        recommended_articles = set(recommend_articles(keywords))\n",
    "        # calculate precision and recall\n",
    "        if len(recommended_articles) > 0:\n",
    "            precision += len(actual_article & recommended_articles) / len(recommended_articles)\n",
    "            recall += len(actual_article & recommended_articles) / len(actual_article)\n",
    "    precision /= len(test_data)\n",
    "    recall /= len(test_data)\n",
    "    f1_score = 2 * precision * recall / (precision + recall)\n",
    "    print('Precision:', precision)\n",
    "    print('Recall:', recall)\n",
    "    print('F1 Score:', f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_system_alt(recommender_function, input_data, true_data, **kwargs):\n",
    "    \"\"\"\n",
    "    Evaluate a recommender system based on precision and recall.\n",
    "\n",
    "    Parameters:\n",
    "        recommender_function (function): A function that takes in an input item and generates a set of recommended items.\n",
    "        input_data (list): A list of input items to test the recommender system.\n",
    "        true_data (dict): A dictionary that maps each input item to a set of true recommended items.\n",
    "        **kwargs: Additional keyword arguments to pass to the recommender function.\n",
    "\n",
    "    Returns:\n",
    "        precision (float): The precision of the recommender system.\n",
    "        recall (float): The recall of the recommender system.\n",
    "    \"\"\"\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    for input_item in input_data:\n",
    "        recommended_items = recommender_function(input_item, **kwargs)\n",
    "        true_items = true_data[input_item]\n",
    "        if len(recommended_items) > 0:\n",
    "            for recommended_item in recommended_items:\n",
    "                if recommended_item in true_items:\n",
    "                    true_positives += 1\n",
    "                else:\n",
    "                    false_positives += 1\n",
    "            for true_item in true_items:\n",
    "                if true_item not in recommended_items:\n",
    "                    false_negatives += 1\n",
    "        else:\n",
    "            false_negatives += len(true_items)\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    #f1_score = 2 * precision * recall / (precision + recall)\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    #print(f\"f1_score: {f1_score:.2f}\")\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1663878                                    Erna slår tilbake\n",
      "1921534      Her kommer Erna Solberg med en budsjettlekkasje\n",
      "359372                       Erna Solberg mintes trafikkofre\n",
      "786810                    Erna sender lærerne på skolebenken\n",
      "984091     Erna Solberg kjørte bil for første gang på tre år\n",
      "1725906    Erna Solberg vil prioritere vekst og arbeidspl...\n",
      "22526        Lysbakken kritisk til Erna Solbergs nyttårstale\n",
      "113307     Trøndersk Høyre-topp mener ulveopprøret kan fe...\n",
      "1328870    Statsminister Erna Solberg til Kaci Kullmann F...\n",
      "1693139    Erna Solberg tror ikke ja til eggdonasjon vill...\n",
      "Name: title, dtype: object\n",
      " \n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "(0.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "#train_df = train_df[:10000]\n",
    "\n",
    "#recommend_articles(\"Erna\", train_df)\n",
    "\n",
    "print(recommend_articles(\"Erna\"))\n",
    "\n",
    "#evaluate_system(test_df, recommend_articles(\"Erna\"))\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print(evaluate_system_alt(recommend_articles, train_data, test_data))\n",
    "\n",
    "#print(recommend_articles(\"Erna\", cosine_sim, df_updated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not used\n",
    "def cosine(df):\n",
    "    tfidf_vectorizer = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0)\n",
    "\n",
    "    # Compute the TF-IDF matrix\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['cleaned_title'])\n",
    "\n",
    "    # Convert the TF-IDF matrix to a sparse matrix\n",
    "    sparse_tfidf_matrix = sp.csr_matrix(tfidf_matrix)\n",
    "\n",
    "    # Compute the cosine similarity matrix\n",
    "    cosine_sim = cosine_similarity(sparse_tfidf_matrix)\n",
    "    \n",
    "    return cosine_sim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tdt4215",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
